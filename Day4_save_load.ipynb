{"cells":[{"cell_type":"code","execution_count":null,"id":"682ec1b3-68e4-4f7f-828e-a51329225849","metadata":{"id":"682ec1b3-68e4-4f7f-828e-a51329225849"},"outputs":[],"source":["import torch\n","import torch.nn as nn"]},{"cell_type":"code","execution_count":null,"id":"b719bf23-05e5-491a-be78-2fa6705f024e","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"b719bf23-05e5-491a-be78-2fa6705f024e","executionInfo":{"status":"ok","timestamp":1716174434381,"user_tz":-480,"elapsed":11,"user":{"displayName":"Tony Luo","userId":"01703475953144684473"}},"outputId":"236f09a6-abf7-45b9-98da-778b3d4bb821"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 4\n","drwxr-xr-x 1 root root 4096 May 16 13:24 sample_data\n"]}],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"id":"84508700-5659-43ca-9abd-71f993ceb626","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"84508700-5659-43ca-9abd-71f993ceb626","executionInfo":{"status":"ok","timestamp":1716174434381,"user_tz":-480,"elapsed":5,"user":{"displayName":"Tony Luo","userId":"01703475953144684473"}},"outputId":"067bfe95-2d33-43bb-a888-35b2655a1ad2"},"outputs":[{"output_type":"stream","name":"stdout","text":["*********** Original Model *************\n","Parameter containing:\n","tensor([[-0.4050,  0.1931,  0.1872, -0.1365,  0.3770, -0.2190],\n","        [ 0.3027, -0.1252,  0.3956,  0.1458, -0.3646, -0.0695],\n","        [ 0.2489,  0.4007, -0.3023,  0.3285, -0.3634,  0.2381],\n","        [-0.1335, -0.2177, -0.1226, -0.1804, -0.4056, -0.2411]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.3521, -0.1276,  0.3366, -0.0815], requires_grad=True)\n","Parameter containing:\n","tensor([[-0.4728,  0.1173,  0.4946,  0.0745],\n","        [-0.1168, -0.4052, -0.3549,  0.2945]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.2332,  0.2292], requires_grad=True)\n","\n","*********** Loaded Model *************\n","Parameter containing:\n","tensor([[-0.4050,  0.1931,  0.1872, -0.1365,  0.3770, -0.2190],\n","        [ 0.3027, -0.1252,  0.3956,  0.1458, -0.3646, -0.0695],\n","        [ 0.2489,  0.4007, -0.3023,  0.3285, -0.3634,  0.2381],\n","        [-0.1335, -0.2177, -0.1226, -0.1804, -0.4056, -0.2411]],\n","       requires_grad=True)\n","Parameter containing:\n","tensor([-0.3521, -0.1276,  0.3366, -0.0815], requires_grad=True)\n","Parameter containing:\n","tensor([[-0.4728,  0.1173,  0.4946,  0.0745],\n","        [-0.1168, -0.4052, -0.3549,  0.2945]], requires_grad=True)\n","Parameter containing:\n","tensor([-0.2332,  0.2292], requires_grad=True)\n","\n","*********** Original Model state dict *************\n","OrderedDict([('fc1.weight', tensor([[-0.4050,  0.1931,  0.1872, -0.1365,  0.3770, -0.2190],\n","        [ 0.3027, -0.1252,  0.3956,  0.1458, -0.3646, -0.0695],\n","        [ 0.2489,  0.4007, -0.3023,  0.3285, -0.3634,  0.2381],\n","        [-0.1335, -0.2177, -0.1226, -0.1804, -0.4056, -0.2411]])), ('fc1.bias', tensor([-0.3521, -0.1276,  0.3366, -0.0815])), ('fc2.weight', tensor([[-0.4728,  0.1173,  0.4946,  0.0745],\n","        [-0.1168, -0.4052, -0.3549,  0.2945]])), ('fc2.bias', tensor([-0.2332,  0.2292]))])\n","\n","*********** Loaded Model state dict *************\n","OrderedDict([('fc1.weight', tensor([[-0.4050,  0.1931,  0.1872, -0.1365,  0.3770, -0.2190],\n","        [ 0.3027, -0.1252,  0.3956,  0.1458, -0.3646, -0.0695],\n","        [ 0.2489,  0.4007, -0.3023,  0.3285, -0.3634,  0.2381],\n","        [-0.1335, -0.2177, -0.1226, -0.1804, -0.4056, -0.2411]])), ('fc1.bias', tensor([-0.3521, -0.1276,  0.3366, -0.0815])), ('fc2.weight', tensor([[-0.4728,  0.1173,  0.4946,  0.0745],\n","        [-0.1168, -0.4052, -0.3549,  0.2945]])), ('fc2.bias', tensor([-0.2332,  0.2292]))])\n"]}],"source":["class Model(nn.Module):\n","    def __init__(self, n_feats):\n","        super(Model, self).__init__()\n","        self.fc1 = nn.Linear(n_feats, 4)\n","        self.fc2 = nn.Linear(4, 2)\n","\n","    def forward(self, x):\n","        x = torch.relu(self.fc1(x))\n","        y = torch.sigmoid(self.fc2(x))\n","        return y\n","\n","model = Model(6)\n","\n","######################### save all ############################\n","print('*********** Original Model *************')\n","for p in model.parameters():\n","    print(p)\n","\n","FILE = 'model.pth'\n","torch.save(model, FILE)\n","\n","loaded_model = torch.load(FILE)\n","loaded_model.eval()\n","\n","print('\\n*********** Loaded Model *************')\n","for p in loaded_model.parameters():\n","    print(p)\n","\n","############################## save only the state dict ###################\n","FILE = 'model_st.pth'\n","torch.save(model.state_dict(), FILE)\n","\n","print('\\n*********** Original Model state dict *************')\n","print(model.state_dict())\n","\n","loaded_model = Model(6)\n","loaded_model.load_state_dict(torch.load(FILE))\n","loaded_model.eval()\n","\n","print('\\n*********** Loaded Model state dict *************')\n","print(loaded_model.state_dict())\n"]},{"cell_type":"code","execution_count":null,"id":"995846c2-e863-403e-85d5-7b07f30d2228","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"995846c2-e863-403e-85d5-7b07f30d2228","executionInfo":{"status":"ok","timestamp":1716174434929,"user_tz":-480,"elapsed":551,"user":{"displayName":"Tony Luo","userId":"01703475953144684473"}},"outputId":"77f8aeb2-c66d-44d3-9127-138aefdc7da6"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 12\n","-rw-r--r-- 1 root root 3008 May 20 03:07 model.pth\n","-rw-r--r-- 1 root root 2136 May 20 03:07 model_st.pth\n","drwxr-xr-x 1 root root 4096 May 16 13:24 sample_data\n"]}],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"id":"f4f98e22-bf05-493b-9052-14cfd8e56e9d","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f4f98e22-bf05-493b-9052-14cfd8e56e9d","executionInfo":{"status":"ok","timestamp":1716174439210,"user_tz":-480,"elapsed":4283,"user":{"displayName":"Tony Luo","userId":"01703475953144684473"}},"outputId":"77b4a1e3-1b12-45f3-c59d-0cfa8c44aba6"},"outputs":[{"output_type":"stream","name":"stdout","text":["************ Original optim state *************\n","{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3]}]}\n","************ Loaded optim state *************\n","{'state': {}, 'param_groups': [{'lr': 0.01, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'foreach': None, 'differentiable': False, 'params': [0, 1, 2, 3]}]}\n"]}],"source":["############## checkpoint #############\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum =0.9)\n","\n","# training..............\n","\n","checkpt = {\n","    'epoch': 100,\n","    'model_st': model.state_dict(),\n","    'optim_st': optimizer.state_dict()\n","}\n","print('************ Original optim state *************')\n","print(optimizer.state_dict())\n","FILE = 'chkpt.pth'\n","torch.save(checkpt, FILE)\n","\n","optimizer = torch.optim.SGD(model.parameters(), lr=0)\n","\n","checkpt_ld = torch.load(FILE)\n","model.load_state_dict(checkpt_ld['model_st'])\n","optimizer.load_state_dict(checkpt_ld['optim_st'])\n","epoch = checkpt_ld['epoch']\n","\n","model.eval()\n","\n","print('************ Loaded optim state *************')\n","print(optimizer.state_dict())\n"]},{"cell_type":"code","execution_count":null,"id":"f9fab338-878c-40c7-ab88-3975b2304274","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"f9fab338-878c-40c7-ab88-3975b2304274","executionInfo":{"status":"ok","timestamp":1716174439210,"user_tz":-480,"elapsed":8,"user":{"displayName":"Tony Luo","userId":"01703475953144684473"}},"outputId":"176f567e-aebe-47ae-f4f2-7cf171938534"},"outputs":[{"output_type":"stream","name":"stdout","text":["total 16\n","-rw-r--r-- 1 root root 2368 May 20 03:07 chkpt.pth\n","-rw-r--r-- 1 root root 3008 May 20 03:07 model.pth\n","-rw-r--r-- 1 root root 2136 May 20 03:07 model_st.pth\n","drwxr-xr-x 1 root root 4096 May 16 13:24 sample_data\n"]}],"source":["!ls -l"]},{"cell_type":"code","execution_count":null,"id":"133d9d04-f80f-4ca0-a898-8f9a0047def0","metadata":{"id":"133d9d04-f80f-4ca0-a898-8f9a0047def0"},"outputs":[],"source":["##################### SAVING ON GPU/CPU ######################\n","# partial code snippet for illustration only; shall not run it\n","##############################################################\n","\n","# 1) Save on GPU, Load on CPU\n","device = torch.device(\"cuda\")\n","model.to(device)\n","torch.save(model.state_dict(), PATH)\n","\n","device = torch.device('cpu')\n","model = Model(*args, **kwargs)\n","model.load_state_dict(torch.load(PATH, map_location=device))\n","\n","# 2) Save on GPU, Load on GPU\n","device = torch.device(\"cuda\")\n","model.to(device)\n","torch.save(model.state_dict(), PATH)\n","\n","model = Model(*args, **kwargs)\n","model.load_state_dict(torch.load(PATH))\n","model.to(device)\n","\n","# Note: Be sure to use the .to(torch.device('cuda')) function\n","# on all model inputs, too!\n","\n","# 3) Save on CPU, Load on GPU\n","torch.save(model.state_dict(), PATH)\n","\n","device = torch.device(\"cuda\")\n","model = Model(*args, **kwargs)\n","model.load_state_dict(torch.load(PATH, map_location=\"cuda:0\"))  # Choose whatever GPU device number you want\n","model.to(device)\n","\n","# This loads the model to a given GPU device.\n","# Next, be sure to call model.to(torch.device('cuda')) to convert the modelâ€™s parameter tensors to CUDA tensors\n","\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}